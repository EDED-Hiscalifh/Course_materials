{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b8e5aa",
   "metadata": {},
   "source": [
    "# Introductions to Parallel Processing \n",
    "\n",
    "## What is Parallel Processing \n",
    "\n",
    "가용 메모리가 한정되어 있는 상황에서 큰 데이터셋을 처리하려면 **청크(Chunk)** 단위로 쪼개어 데이터를 처리해야 했다. **병렬 처리(Parallel Processing)**은 청크를 동시에 처리하여 작업의 속도를 증가시킨다. \n",
    "\n",
    "**중앙 처리 장치(Centeral Processing Unit; CPU)**는 컴퓨터 연산을 처리하는 하드웨어이다. 예전의 CPU는 단일 코어로 한가지의 작업만 수행할 수 있었지만, 현재의 CPU는 멀티 코어를 사용하여 병렬 처리 작업이 가능하게 되었다. \n",
    "\n",
    "Python의 multiprocessing 모듈은 병렬 처리를 가능하게 하는 패키지를 제공한다.\n",
    "\n",
    "```Python\n",
    "import multiprocessing \n",
    "```\n",
    "\n",
    "## Process \n",
    "\n",
    "### Process.start() \n",
    "\n",
    "multiprocessing의 Process() 메소드는 Process 객체를 생성하여 병렬 처리를 위한 프로세스를 생성한다. Process() 메소드의 target parameter는 처리해야 하는 프로세스(함수)를 입력한다. 생성된 Process 객체는 start() 메소드를 통해 실행된다.\n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "process = multiprocessing.Process(target=wait)\n",
    "\n",
    "# Add code here\n",
    "process.start()\n",
    "print(\"Finished\")\n",
    "process.join()\n",
    "```\n",
    "\n",
    "### Process.join()\n",
    "\n",
    "해당 프로그램의 실행결과 \"Finished\"가 먼저 출력되고 \"Done waiting\"이 실행된다. Python IDE는 노출되어 있는 순으로 코드를 진행하여, Process.start() 이후 병렬 실행된 wait() 함수가 time.sleep()에 의해 지연 되면서 print(\"Finished\")가 먼저 실행되었기 때문이다. 이후 Process.join()은 지속되고 있는 프로세스를 종료해 기다리고 있는 다른 프로세스를 실행히키고자 할 때 사용된다. 따라서 원하는 결과를 산출하기 위한 코드는 다음과 같다. \n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "process = multiprocessing.Process(target=wait)\n",
    "\n",
    "# Add code below\n",
    "\n",
    "process.start()\n",
    "process.join()\n",
    "print(\"Finished\")\n",
    "```\n",
    "\n",
    "## Execution time of Parallele Processing \n",
    "\n",
    "병렬 처리의 연산 속도 향상을 위한 workflow는 아래와 같다. 아래의 workflow에서 메인 프로그램은 모든 프로세스가 종료될때까지 기다리고 각각의 결과를 종합하여 전체 결과를 출력하게 된다. 하지만 각각의 프로세스는 병렬적으로 시행되기 때문에 수행시간은 프로세스의 수로 나누어저 시행되게 된다. \n",
    "\n",
    "1. 각각의 연산을 chunk들로 나눈다. \n",
    "2. 각각의 chunk에 대해 프로세스를 시행한다.\n",
    "3. 모든 프로세스가 종료될때까 기다린다. \n",
    "4. 결과를 종합한다. \n",
    "\n",
    "```Python\n",
    "import time\n",
    "def wait():\n",
    "    time.sleep(0.5)\n",
    "    print(\"Done waiting\")\n",
    "\n",
    "# Add code below\n",
    "start = time.time()\n",
    "wait()\n",
    "end = time.time()\n",
    "elapsed1 = end - start\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "p1 = multiprocessing.Process(target = wait)\n",
    "p2 = multiprocessing.Process(target = wait)\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "end = time.time()\n",
    "elapsed2 = end - start\n",
    "```\n",
    "\n",
    "시행결과 elapsed1과 elapsed2는 거의 차이가 없다. \n",
    "\n",
    "## Parallel Processing with arguments \n",
    "\n",
    "어떤 프로세스에 구성된 함수에 입력값이 필요한 경우가 있는 경우, Process() 메소드는 target parameter외에 args parameter를 통해 해당 함수의 arguments를 입력받을 수 있다. 또한 입력받은 arguments는 iterable하기 때문에 객체의 형태를 그대로 대입할 수 있다.\n",
    "\n",
    "```Python\n",
    "def sum3(x, y, z):\n",
    "    print(x + y + z)\n",
    "\n",
    "def list_average(values):\n",
    "    print(sum(values) / len(values))\n",
    "\n",
    "# Add code below\n",
    "\n",
    "sum3_process = multiprocessing.Process(target = sum3, args = [3, 2, 5])\n",
    "list_average_process = multiprocessing.Process(target = list_average, args = [[1, 2, 3, 4, 5]])\n",
    "\n",
    "sum3_process.start()\n",
    "list_average_process.start()\n",
    "sum3_process.join()\n",
    "list_average_process.join()\n",
    "```\n",
    "\n",
    "## Shared memory \n",
    "\n",
    "앞선 방식의 프로세스는 함수의 값을 받을 수 없다. 함수는 독립적인 프로세스에서 실행되고 있기 때문에 각각의 메모리에  존재하며 다른 프로세스와 값을 공유하지 못한다. **Shared memory** 방식은 값을 return하는 대신에 결과값을 shared memory 위치에 저장하고 있어 값을 저장할 수 있다. \n",
    "\n",
    "multiprocessing.Value 객체는 함수를 정의할 때 함수의 argument 형태로 작성되어 값을 접근하고 사용할 수 있도록 한다. 해당 값을 access 하는 방식은 Value.value 속성을 통해 가능하다. 프로세스를 생성하기 이전에 Value 또한 정의되어야 하는데, Value() 메소드 내부에 데이터 타입을 정의할 필요가 있다. 이후에 생성된 객체를 args prameter에 추가적으로 입력하면 된다. \n",
    "\n",
    "```Python\n",
    "def sum3(x, y, z, shared_value) : \n",
    "    shared_value.value = x + y + z \n",
    "    \n",
    "\n",
    "float_value = multiprocessing.Value(\"f\")\n",
    "process = multiprocessing.Process(target = sum3, args = [5, 7, 4, float_value])\n",
    "process.start()\n",
    "process.end()\n",
    "print(float_value) \n",
    "```\n",
    "\n",
    "## Cautions of sharing value \n",
    "\n",
    "multiprocessing.Value는 single value만 저장할 수 있다. 따라서 프로세스 사이에서 shared memory를 사용할 때 동시에 값을 업데이트 하지 않도록 주의해야 한다. 예를들어 1 ~ 10000까지의 수를 더하는 프로세스를 1 ~ 4999, 5000 ~ 10000까지 계산하는 두 개의 병렬 프로세스로 분할하여 처리한다고 할때 하나의 shared value만 사용하게 되면 각각의 프로세스에서 처리된 값이 서로 shared memory에 업데이트 되는 문제가 발생한다.\n",
    "\n",
    "```Python\n",
    "def sum_values(first, last, shared_value):\n",
    "    for i in range(first, last):\n",
    "        shared_value.value += i\n",
    "\n",
    "def sum_with_two_processes():\n",
    "    N = 10000\n",
    "\n",
    "    shared_value = multiprocessing.Value(\"i\")\n",
    "    process1 = multiprocessing.Process(target=sum_values, args=(1, N // 2, shared_value))\n",
    "    process2 = multiprocessing.Process(target=sum_values, args=(N // 2, N, shared_value))\n",
    "\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    return shared_value.value\n",
    "\n",
    "# Add code below\n",
    "\n",
    "results = []\n",
    "for _ in range(10) : \n",
    "    results.append(sum_with_two_processes())\n",
    "\n",
    "print(results)\n",
    "```\n",
    "\n",
    "## Using lock to prevent overwitting \n",
    "\n",
    "multiprocess를 사용하면서 발생하는 shared memory에 값을 덮어쓰는 문제는 **lock**을 통해 해결할 수 있다. lock은 병렬처리에서 각각의 프로세스의 자원을 통제하는 매커니즘으로, 다른 프로세스가 각 자원에 서로 간섭하는 것을 방지하도록 한다. 해당 작업은 Value.get_loc() 메소드를 사용함으로써 가능하다. \n",
    "\n",
    "하지만 이 방식은 병렬처리의 이점을 더이상 살리지 못한다. 다른 프로세스 해당 프로세스가 잠겨있는 동안 shared memory에 접근할 수 없기 때문이다. 이는 지역변수를 설정하고 지역변수의 값에 업데이트 하는 방식으로 해결할 수 있다. \n",
    "\n",
    "```Python\n",
    "def sum_values(first, last, shared_value):\n",
    "    for i in range(first, last):\n",
    "        with shared_value.get_lock():\n",
    "            shared_value.value += i\n",
    "            \n",
    "def sum_values_improved(first, last, shared_value) : \n",
    "    value_sum = 0\n",
    "    for i in range(first, last) : \n",
    "        value_sum += i \n",
    "    with shared_value.get_lock() : \n",
    "        shared_value.value = value_sum\n",
    "\n",
    "def measure_runtime(function_to_measure):\n",
    "    N = 10000\n",
    "    shared_value = multiprocessing.Value(\"i\")\n",
    "    process1 = multiprocessing.Process(target=function_to_measure, args=(1, N // 2, shared_value))\n",
    "    process2 = multiprocessing.Process(target=function_to_measure, args=(N // 2, N, shared_value))\n",
    "    start = time.time()\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "    \n",
    "# Whole calculation\n",
    "start = time.time()\n",
    "res = 0\n",
    "for i in range(1, 10000) : \n",
    "    res += i\n",
    "end = time.time()\n",
    "elapsed1 = end - start \n",
    "\n",
    "time_sum_values = measure_runtime(sum_values) \n",
    "time_sum_values_improved = measure_runtime(sum_values_improved)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d665d41",
   "metadata": {},
   "source": [
    "# Process Pool Executors\n",
    "\n",
    "## Make frequency table of each languages \n",
    "\n",
    "job_postings 데이터테이블에 작성되어 있는 언어별 빈도수 테이블을 생성하려고 한다. Series.str.count() 메소드는 행을 기준으로 각 행의 count에 입력된 argument가 얼마나 반복되었는지를 계산한다. 이후 sum() 메소드를 통해 언어별 총 빈도수를 확인할 수 있다.\n",
    "\n",
    "\n",
    "```Python\n",
    "import pandas as pd \n",
    "job_postings = pd.read_csv('DataEngineer.csv') \n",
    "num_rows = job_postings.shape[0]\n",
    "num_cols = job_postings.shape[1]\n",
    "\n",
    "job_postings[\"Job Description\"] = job_postings[\"Job Description\"].str.lower()\n",
    "\n",
    "# Make frequency table \n",
    "skills = pd.read_csv('Skills.csv')\n",
    "frequency = {}\n",
    "\n",
    "for skill_name in skills[\"Name\"] : \n",
    "    frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "print(frequency[\"programming\"])\n",
    "```\n",
    "\n",
    "## Function of frequency table \n",
    "\n",
    "병렬처리를 위한 첫 단계는 코드를 함수로 변환하는 작업이다. 빈도표를 작성하는 코드를 job_postings와 skills를 입력받는 count_skills() 내부에 작성하여 함수를 생성한다.\n",
    "\n",
    "```Python\n",
    "import time\n",
    "\n",
    "def count_skills(job_postings, skills) : \n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"]:\n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "    \n",
    "start = time.time()\n",
    "count_skills(job_postings, skills) \n",
    "end = time.time()\n",
    "runtime = end - start\n",
    "print(runtime)\n",
    "```\n",
    "\n",
    "## Function of dataframe chunk\n",
    "\n",
    "데이터셋이 가용 메모리에 적합하지 않을 경우 청크 단위로 나누어 데이터를 처리하였다. 따라서 병렬처리를 위한 데이터셋을 청크 단위로 분해하는 함수를 작성한다. 입력된 청크의 수에 따라 처리해야하는 청크의 크기는 math.ceil() 메소드를 통해 계산하고 ragne(0, num_rows, chunk_size)를 통해 데이터 셋을 분할할 수 있다. \n",
    "\n",
    "```Python\n",
    "import math\n",
    "def math_chunks(df, num_chunks) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows/num_chunks)\n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "    \n",
    "skill_chunks = math_chunks(skills, 8)\n",
    "```\n",
    "\n",
    "## Process Pool Executor\n",
    "\n",
    "Job Description에 기술되어 있는 언어에 대한 빈도표를 청크 단위로 병렬 처리하는 workflow는 아래와 같다.\n",
    "\n",
    "1. split the data into chunks \n",
    "2. create a process list, one for each chunk\n",
    "3. run all processes and wait for them to finish \n",
    "4. gather the results and merge them into a single frequency table \n",
    "\n",
    "4번째 단계의 경우 multiprocessing.Value 객체는 하나의 값만 저장하기 때문에 문제가 발생할 수 있다. concurrent.futures 모듈은 실행된 각각의 프로세스의 값을 리스트의 형태로 저장할 수 있다. concurrent.futures.ProcessPoolExecutor context manager는 각각의 프로세스를 함수, 입력값을 입력받아 실행하여 값을 list의 형태로 저장할 수 있다. 프로세스를 실행하기 위해 Executor.submit() 메소드를 사용하여 with statement 내부에서 작동하기 때문에 프로세스를 자동 종료시킨다. Executor.submit()으로 생성된 Future 객체는 Future.result()를 통해 결과를 불러올 수 있다. \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "\n",
    "def increment(value):\n",
    "    return value + 1\n",
    "\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(increment, value) for value in values] \n",
    "    \n",
    "results = [future.result() for future in futures]\n",
    "```\n",
    "\n",
    "## Parallel Processing of frequency table \n",
    "\n",
    "1. job_postings 데이터프레임을 분할하고 각각의 청크에 있는 모든 skill을 샌다. 각각의 프로세스는 job_posting의 부분을 입력받아 빈도표를 작성한다.\n",
    "2. skills를 분할하여 각 청크에 대해 job_postings 천체 데이터프레임에 대해 분할표를 작성한다. \n",
    "\n",
    "### First case \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "def count_skills(df, skills) :\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"] : \n",
    "        frequency[skill_name] = df[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def make_chunks(df, chunk_size) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows / chunk_size) \n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "\n",
    "job_chunks = make_chunks(job_postings, 8) \n",
    "with current.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(count_skills, job_chunk, skills) for job_chunk in job_chunks]\n",
    "results = [future.result() for future in futures]\n",
    "\n",
    "merged_results = {} \n",
    "for result in results : \n",
    "    for language in result : \n",
    "        if language in merged_results : \n",
    "            merged_results[language] += result[language]\n",
    "        else : \n",
    "            merged_results[language] = result[language] \n",
    "```\n",
    "\n",
    "### Second case \n",
    "\n",
    "```Python\n",
    "import concurrent.futures\n",
    "import pandas as pd \n",
    "import math \n",
    "\n",
    "def count_skills(job_postings, skills) :\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"] : \n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def make_chunks(df, chunk_size) : \n",
    "    num_rows = df.shape[0]\n",
    "    chunk_size = math.ceil(num_rows / chunk_size) \n",
    "    return [df[i:i+chunk_size] for i in range(0, num_rows, chunk_size)]\n",
    "\n",
    "skill_chunks = make_chunks(skills, 8) \n",
    "with concurrent.futures.ProcessPoolExecutor() as executor : \n",
    "    futures = [executor.submit(count_skills, job_postings, skill_chunk) for skill_chunk in skill_chunks]\n",
    "results = [future.result() for future in futures]\n",
    "\n",
    "merged_results = {}\n",
    "\n",
    "for result in results : \n",
    "    merged_results.update(result) \n",
    "print(merged_results)\n",
    "```\n",
    "\n",
    "## Time Comparison\n",
    "\n",
    "```Python\n",
    "def count_skills(job_postings, skills):\n",
    "    frequency = {}\n",
    "    for skill_name in skills[\"Name\"]:\n",
    "        frequency[skill_name] = job_postings[\"Job Description\"].str.count(skill_name).sum()\n",
    "    return frequency\n",
    "\n",
    "def count_skills_parallel(job_postings, skills, num_processes=4):\n",
    "    # Calculate results using paralleld processing\n",
    "    skill_chunks = make_chunks(skills, num_processes)\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(count_skills, job_postings, skill_chunk) for skill_chunk in skill_chunks]\n",
    "    results = [future.result() for future in futures]\n",
    "    # Merge results\n",
    "    merged_results = {}\n",
    "    for result in results:\n",
    "        merged_results.update(result)\n",
    "    return merged_results\n",
    "\n",
    "import time\n",
    "\n",
    "# Measure execution times \n",
    "start = time.time()\n",
    "count_skills(job_postings, skills)\n",
    "end = time.time()\n",
    "time_normal = end - start \n",
    "\n",
    "start = time.time()\n",
    "count_skills_parallel(job_postings, skills, num_processes = 4)\n",
    "end = time.time()\n",
    "time_parallel = end - start\n",
    "\n",
    "print(time_normal/time_parallel)\n",
    "```\n",
    "\n",
    "병렬처리를 한 경우가 하지 않은 경우에 비해 2배가량 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85a31d",
   "metadata": {},
   "source": [
    "# Introduction to MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef7808",
   "metadata": {},
   "source": [
    "# Processing data with MapReduce"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
